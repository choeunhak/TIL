{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#txt파일을 tab을 딜리미터로 하여 불러오기\n",
    "df_train=pd.read_csv('data/ratings_train.txt', delimiter = '\\t', keep_default_na=False)\n",
    "df_test=pd.read_csv('data/ratings_test.txt', delimiter = '\\t', keep_default_na=False)\n",
    "\n",
    "#train 데이터 data와 label로 분리\n",
    "text_train = df_train['document']\n",
    "y_train = df_train['label']\n",
    "\n",
    "#test 데이터 data와 label로 분리\n",
    "text_test = df_test['document']\n",
    "y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-5fa063ca0178>:18: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  filtered_train=pd.Series([])\n",
      "<ipython-input-25-5fa063ca0178>:19: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  filtered_test=pd.Series([])\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "twitter_tag=Okt()\n",
    "\n",
    "#normalization과 stemming을 하고 word[1]이 Josa, Eomi, Punctuation, Korean Particle인 경우에 삭제하고 리스트에 append하고 return하는\n",
    "#tokenizer 정의\n",
    "def twitter_tokenizer(text):\n",
    "    malist = twitter_tag.pos(text,norm=True, stem=True)\n",
    "    r=[]\n",
    "    for word in malist:\n",
    "        if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\", \"KoreanParticle\"]:\n",
    "            r.append(word[0])\n",
    "    return r\n",
    "\n",
    "filtered_train=pd.Series([])\n",
    "filtered_test=pd.Series([])\n",
    "\n",
    "#text_train의 데이터를 반복하면서 twitter_tokenizer로 Josa, Eomi, Punctuation, Korean Particle를 삭제한후\n",
    "#다시 형태소 사이에 빈 칸을 하나 넣고 join한 후 pandas Series로 형 변환후에 새로운 Series에 append시켰다.\n",
    "for data in text_train:\n",
    "    temp=pd.Series(' '.join(twitter_tokenizer(data)))\n",
    "    filtered_train=filtered_train.append(temp, ignore_index=True)\n",
    "\n",
    "#text_test의 데이터를 반복하면서 twitter_tokenizer로 Josa, Eomi, Punctuation, Korean Particle를 삭제한후\n",
    "#다시 형태소 사이에 빈 칸을 하나 넣고 join한 후 pandas Series로 형 변환후에 새로운 Series에 append시켰다.\n",
    "for data in text_test:\n",
    "    temp=pd.Series(' '.join(twitter_tokenizer(data)))\n",
    "    filtered_test=filtered_test.append(temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Josa, Eomi, Punctuation, Korean Particle 삭제 전\n",
      "0                                                  굳 ㅋ\n",
      "1                                 GDNTOPCLASSINTHECLUB\n",
      "2               뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n",
      "3                     지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n",
      "4    3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n",
      "Name: document, dtype: object\n",
      "\n",
      "Josa, Eomi, Punctuation, Korean Particle 삭제 후\n",
      "0                                              굳다\n",
      "1                            GDNTOPCLASSINTHECLUB\n",
      "2              뭐 이 평점 들 나쁘다 않다 10 점 짜다 리 더 더욱 아니다\n",
      "3                         지루하다 않다 완전 막장 임 돈 주다 보기\n",
      "4    3 D 만 아니다 별 다섯 개 주다 왜 3 D 로 나오다 제 심기 불편하다 하다\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Josa, Eomi, Punctuation, Korean Particle 삭제 전\")\n",
    "print(text_test[0:5])\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Josa, Eomi, Punctuation, Korean Particle 삭제 후\")\n",
    "print(filtered_test[0:5])\n",
    "\n",
    "\n",
    "#2번째 인덱스를 보면 ' 뭐야 이 평점들은.... 나쁘진 않지만'이 '뭐 이 평점 들 나쁘다 않다'가 되었다\n",
    "#따라서 \"야\", \",\"과 같은 조사, 어미 punctuation, KoreanParticle은 제거가 된 모습이고 \n",
    "#'나쁘진'이 형용사의 기본형인 '나쁘다'가 되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choeunhak\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "twitter_tag=Okt()\n",
    "\n",
    "#Josa, Eomi, Punctuation, Korean Particle를 삭제하는 tokenizer 정의\n",
    "def twitter_tokenizer(text):\n",
    "    malist = twitter_tag.pos(text,norm=True, stem=True)\n",
    "    r=[]\n",
    "    for word in malist:\n",
    "        if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\", \"KoreanParticle\"]:\n",
    "            r.append(word[0])\n",
    "    return r\n",
    "\n",
    "#TfidfVectorizer를 사용하여 BOW 생성\n",
    "vect=TfidfVectorizer(tokenizer=twitter_tokenizer).fit(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 37720)\t0.45785907908518\n",
      "  (0, 37494)\t0.3043279726856257\n",
      "  (0, 26275)\t0.37510430072242007\n",
      "  (0, 16655)\t0.5396067903097983\n",
      "  (0, 11843)\t0.5156266325272867\n",
      "  (1, 46005)\t0.3948219173669031\n",
      "  (1, 42674)\t0.3522650790151567\n",
      "  (1, 38884)\t0.36713758055435725\n",
      "  (1, 36778)\t0.309200714156536\n",
      "  (1, 29661)\t0.4233878861081901\n",
      "  (1, 29354)\t0.12111034807737996\n",
      "  (1, 29020)\t0.22562831303223427\n",
      "  (1, 27015)\t0.21424311144041985\n",
      "  (1, 19632)\t0.2409765070504278\n",
      "  (1, 4169)\t0.375269158174095\n",
      "  (2, 39282)\t0.24341478139264053\n",
      "  (2, 19663)\t0.10585486079731403\n",
      "  (2, 17905)\t0.5070257916043699\n",
      "  (2, 17098)\t0.4782784452334599\n",
      "  (2, 14027)\t0.4158988596181004\n",
      "  (2, 10898)\t0.4039676328694152\n",
      "  (2, 10887)\t0.18341423585008926\n",
      "  (2, 9961)\t0.2718751117111555 \n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_train=vect.transform(text_train)\n",
    "\n",
    "#BOW의 일부를 sparse matrix 형태로 출력\n",
    "print(x_train[0:3], \"\\n\")\n",
    "\n",
    "#BOW의 일부를 array 형태로 출력\n",
    "print(x_train[0:3].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 =  0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "#Multinomial Naive Bayesian classification을 사용하여 분류 모델을 train 시킴\n",
    "clf_mult=MultinomialNB().fit(x_train,y_train)\n",
    "\n",
    "x_test = vect.transform(text_test)\n",
    "\n",
    "#x_test로 predict 실행\n",
    "pre=clf_mult.predict(x_test)\n",
    "\n",
    "#정답률 산출 및 소수점 둘째짜리에서 반올림\n",
    "ac_score=metrics.accuracy_score(y_test,pre)\n",
    "print(\"정답률 = \", round(ac_score, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "알파값 1.01 정답률 0.83748\n",
      "알파값 1.02 정답률 0.8376\n",
      "알파값 1.03 정답률 0.83778\n",
      "알파값 1.04 정답률 0.83768\n",
      "알파값 1.05 정답률 0.8377\n",
      "알파값 1.06 정답률 0.8378\n",
      "알파값 1.07 정답률 0.83778\n",
      "알파값 1.08 정답률 0.83778\n",
      "알파값 1.09 정답률 0.83776\n",
      "알파값 1.1 정답률 0.83778\n",
      "알파값 1.11 정답률 0.8378\n",
      "알파값 1.12 정답률 0.83784\n",
      "알파값 1.13 정답률 0.83778\n",
      "알파값 1.14 정답률 0.83782\n",
      "알파값 1.15 정답률 0.83786\n",
      "알파값 1.16 정답률 0.8379\n",
      "알파값 1.17 정답률 0.83798\n",
      "알파값 1.18 정답률 0.83808\n",
      "알파값 1.19 정답률 0.83818\n",
      "알파값 1.2 정답률 0.83822\n",
      "알파값 1.21 정답률 0.83824\n",
      "알파값 1.22 정답률 0.8383\n",
      "알파값 1.23 정답률 0.83824\n",
      "알파값 1.24 정답률 0.83818\n",
      "알파값 1.25 정답률 0.83824\n",
      "알파값 1.26 정답률 0.8382\n",
      "알파값 1.27 정답률 0.83826\n",
      "알파값 1.28 정답률 0.8383\n",
      "알파값 1.29 정답률 0.8383\n",
      "알파값 1.3 정답률 0.83836\n",
      "알파값 1.31 정답률 0.83838\n",
      "알파값 1.32 정답률 0.83842\n",
      "알파값 1.33 정답률 0.83844\n",
      "알파값 1.34 정답률 0.83846\n",
      "알파값 1.35 정답률 0.83856\n",
      "알파값 1.36 정답률 0.83862\n",
      "알파값 1.37 정답률 0.8386\n",
      "알파값 1.38 정답률 0.83858\n",
      "알파값 1.39 정답률 0.83862\n",
      "알파값 1.4 정답률 0.83856\n",
      "알파값 1.41 정답률 0.83854\n",
      "알파값 1.42 정답률 0.83852\n",
      "알파값 1.43 정답률 0.83852\n",
      "알파값 1.44 정답률 0.83858\n",
      "알파값 1.45 정답률 0.8386\n",
      "알파값 1.46 정답률 0.83858\n",
      "알파값 1.47 정답률 0.83854\n",
      "알파값 1.48 정답률 0.83854\n",
      "알파값 1.49 정답률 0.83864\n",
      "알파값 1.5 정답률 0.83864\n",
      "알파값 1.51 정답률 0.8386\n",
      "알파값 1.52 정답률 0.83862\n",
      "알파값 1.53 정답률 0.83862\n",
      "알파값 1.54 정답률 0.83858\n",
      "알파값 1.55 정답률 0.83854\n",
      "알파값 1.56 정답률 0.83848\n",
      "알파값 1.57 정답률 0.83852\n",
      "알파값 1.58 정답률 0.8386\n",
      "알파값 1.59 정답률 0.83874\n",
      "알파값 1.6 정답률 0.83874\n",
      "알파값 1.61 정답률 0.8388\n",
      "알파값 1.62 정답률 0.83884\n",
      "알파값 1.63 정답률 0.83882\n",
      "알파값 1.64 정답률 0.8388\n",
      "알파값 1.65 정답률 0.83888\n",
      "알파값 1.66 정답률 0.83894\n",
      "알파값 1.67 정답률 0.83888\n",
      "알파값 1.68 정답률 0.8389\n",
      "알파값 1.69 정답률 0.83894\n",
      "알파값 1.7 정답률 0.83896\n",
      "알파값 1.71 정답률 0.83894\n",
      "알파값 1.72 정답률 0.8389\n",
      "알파값 1.73 정답률 0.83894\n",
      "알파값 1.74 정답률 0.839\n",
      "알파값 1.75 정답률 0.83906\n",
      "알파값 1.76 정답률 0.83906\n",
      "알파값 1.77 정답률 0.8391\n",
      "알파값 1.78 정답률 0.83918\n",
      "알파값 1.79 정답률 0.8392\n",
      "알파값 1.8 정답률 0.83916\n",
      "알파값 1.81 정답률 0.83918\n",
      "알파값 1.82 정답률 0.83904\n",
      "알파값 1.83 정답률 0.839\n",
      "알파값 1.84 정답률 0.839\n",
      "알파값 1.85 정답률 0.83906\n",
      "알파값 1.86 정답률 0.839\n",
      "알파값 1.87 정답률 0.83894\n",
      "알파값 1.88 정답률 0.83904\n",
      "알파값 1.89 정답률 0.83904\n",
      "알파값 1.9 정답률 0.8391\n",
      "알파값 1.91 정답률 0.83908\n",
      "알파값 1.92 정답률 0.83906\n",
      "알파값 1.93 정답률 0.83908\n",
      "알파값 1.94 정답률 0.83912\n",
      "알파값 1.95 정답률 0.83914\n",
      "알파값 1.96 정답률 0.83912\n",
      "알파값 1.97 정답률 0.83918\n",
      "알파값 1.98 정답률 0.83918\n",
      "알파값 1.99 정답률 0.83916\n",
      "알파값 2.0 정답률 0.83918\n",
      "알파값 2.01 정답률 0.83916\n",
      "알파값 2.02 정답률 0.83916\n",
      "알파값 2.03 정답률 0.8392\n",
      "알파값 2.04 정답률 0.8392\n",
      "알파값 2.05 정답률 0.83918\n",
      "알파값 2.06 정답률 0.8392\n",
      "알파값 2.07 정답률 0.83924\n",
      "알파값 2.08 정답률 0.8392\n",
      "알파값 2.09 정답률 0.8392\n",
      "알파값 2.1 정답률 0.83916\n",
      "알파값 2.11 정답률 0.8392\n",
      "알파값 2.12 정답률 0.83922\n",
      "알파값 2.13 정답률 0.83926\n",
      "알파값 2.14 정답률 0.8392\n",
      "알파값 2.15 정답률 0.83922\n",
      "알파값 2.16 정답률 0.83924\n",
      "알파값 2.17 정답률 0.83918\n",
      "알파값 2.18 정답률 0.83922\n",
      "알파값 2.19 정답률 0.83922\n",
      "알파값 2.2 정답률 0.83918\n",
      "알파값 2.21 정답률 0.83922\n",
      "알파값 2.22 정답률 0.8392\n",
      "알파값 2.23 정답률 0.83914\n",
      "알파값 2.24 정답률 0.83918\n",
      "알파값 2.25 정답률 0.8392\n",
      "알파값 2.26 정답률 0.83914\n",
      "알파값 2.27 정답률 0.8392\n",
      "알파값 2.28 정답률 0.83916\n",
      "알파값 2.29 정답률 0.8392\n",
      "알파값 2.3 정답률 0.83916\n",
      "알파값 2.31 정답률 0.8392\n",
      "알파값 2.32 정답률 0.83922\n",
      "알파값 2.33 정답률 0.8392\n",
      "알파값 2.34 정답률 0.83912\n",
      "알파값 2.35 정답률 0.83914\n",
      "알파값 2.36 정답률 0.83916\n",
      "알파값 2.37 정답률 0.83914\n",
      "알파값 2.38 정답률 0.83912\n",
      "알파값 2.39 정답률 0.83916\n",
      "알파값 2.4 정답률 0.83918\n",
      "알파값 2.41 정답률 0.83926\n",
      "알파값 2.42 정답률 0.83926\n",
      "알파값 2.43 정답률 0.83926\n",
      "알파값 2.44 정답률 0.83926\n",
      "알파값 2.45 정답률 0.83926\n",
      "알파값 2.46 정답률 0.83922\n",
      "알파값 2.47 정답률 0.83918\n",
      "알파값 2.48 정답률 0.83922\n",
      "알파값 2.49 정답률 0.83918\n",
      "알파값 2.5 정답률 0.8392\n",
      "알파값 2.51 정답률 0.83918\n",
      "알파값 2.52 정답률 0.8392\n",
      "알파값 2.53 정답률 0.83924\n",
      "알파값 2.54 정답률 0.83922\n",
      "알파값 2.55 정답률 0.8392\n",
      "알파값 2.56 정답률 0.83922\n",
      "알파값 2.57 정답률 0.83924\n",
      "알파값 2.58 정답률 0.83924\n",
      "알파값 2.59 정답률 0.83922\n",
      "알파값 2.6 정답률 0.83918\n",
      "알파값 2.61 정답률 0.83918\n",
      "알파값 2.62 정답률 0.83922\n",
      "알파값 2.63 정답률 0.8392\n",
      "알파값 2.64 정답률 0.8392\n",
      "알파값 2.65 정답률 0.83914\n",
      "알파값 2.66 정답률 0.83912\n",
      "알파값 2.67 정답률 0.83912\n",
      "알파값 2.68 정답률 0.83912\n",
      "알파값 2.69 정답률 0.83912\n",
      "알파값 2.7 정답률 0.83914\n",
      "알파값 2.71 정답률 0.83912\n",
      "알파값 2.72 정답률 0.83914\n",
      "알파값 2.73 정답률 0.83916\n",
      "알파값 2.74 정답률 0.83914\n",
      "알파값 2.75 정답률 0.8391\n",
      "알파값 2.76 정답률 0.8391\n",
      "알파값 2.77 정답률 0.83908\n",
      "알파값 2.78 정답률 0.83906\n",
      "알파값 2.79 정답률 0.83908\n",
      "알파값 2.8 정답률 0.83904\n",
      "알파값 2.81 정답률 0.83904\n",
      "알파값 2.82 정답률 0.839\n",
      "알파값 2.83 정답률 0.83902\n",
      "알파값 2.84 정답률 0.83898\n",
      "알파값 2.85 정답률 0.83894\n",
      "알파값 2.86 정답률 0.83896\n",
      "알파값 2.87 정답률 0.83894\n",
      "알파값 2.88 정답률 0.83894\n",
      "알파값 2.89 정답률 0.839\n",
      "알파값 2.9 정답률 0.83898\n",
      "알파값 2.91 정답률 0.83906\n",
      "알파값 2.92 정답률 0.8391\n",
      "알파값 2.93 정답률 0.83908\n",
      "알파값 2.94 정답률 0.83914\n",
      "알파값 2.95 정답률 0.83912\n",
      "알파값 2.96 정답률 0.83912\n",
      "알파값 2.97 정답률 0.83914\n",
      "알파값 2.98 정답률 0.83918\n",
      "알파값 2.99 정답률 0.83918\n",
      "알파값 3.0 정답률 0.83918\n",
      "알파값 3.01 정답률 0.83918\n",
      "알파값 3.02 정답률 0.83922\n",
      "알파값 3.03 정답률 0.83922\n",
      "알파값 3.04 정답률 0.83916\n",
      "알파값 3.05 정답률 0.8391\n",
      "알파값 3.06 정답률 0.8391\n",
      "알파값 3.07 정답률 0.83912\n",
      "알파값 3.08 정답률 0.83914\n",
      "알파값 3.09 정답률 0.83908\n",
      "알파값 3.1 정답률 0.83912\n",
      "알파값 3.11 정답률 0.83912\n",
      "알파값 3.12 정답률 0.83914\n",
      "알파값 3.13 정답률 0.83916\n",
      "알파값 3.14 정답률 0.83918\n",
      "알파값 3.15 정답률 0.83918\n",
      "알파값 3.16 정답률 0.83914\n",
      "알파값 3.17 정답률 0.83908\n",
      "알파값 3.18 정답률 0.83902\n",
      "알파값 3.19 정답률 0.83906\n",
      "알파값 3.2 정답률 0.8391\n",
      "알파값 3.21 정답률 0.83906\n",
      "알파값 3.22 정답률 0.8391\n",
      "알파값 3.23 정답률 0.83912\n",
      "알파값 3.24 정답률 0.83908\n",
      "알파값 3.25 정답률 0.8391\n",
      "알파값 3.26 정답률 0.83904\n",
      "알파값 3.27 정답률 0.839\n",
      "알파값 3.28 정답률 0.83902\n",
      "알파값 3.29 정답률 0.83902\n",
      "알파값 3.3 정답률 0.83902\n",
      "알파값 3.31 정답률 0.83898\n",
      "알파값 3.32 정답률 0.83896\n",
      "알파값 3.33 정답률 0.83894\n",
      "알파값 3.34 정답률 0.83894\n",
      "알파값 3.35 정답률 0.83894\n",
      "알파값 3.36 정답률 0.83896\n",
      "알파값 3.37 정답률 0.83896\n",
      "알파값 3.38 정답률 0.83898\n",
      "알파값 3.39 정답률 0.839\n",
      "알파값 3.4 정답률 0.839\n",
      "알파값 3.41 정답률 0.83902\n",
      "알파값 3.42 정답률 0.83902\n",
      "알파값 3.43 정답률 0.839\n",
      "알파값 3.44 정답률 0.839\n",
      "알파값 3.45 정답률 0.83904\n",
      "알파값 3.46 정답률 0.83912\n",
      "알파값 3.47 정답률 0.8391\n",
      "알파값 3.48 정답률 0.83912\n",
      "알파값 3.49 정답률 0.83912\n",
      "알파값 3.5 정답률 0.83912\n",
      "알파값 3.51 정답률 0.83908\n",
      "알파값 3.52 정답률 0.83908\n",
      "알파값 3.53 정답률 0.83912\n",
      "알파값 3.54 정답률 0.83912\n",
      "알파값 3.55 정답률 0.83914\n",
      "알파값 3.56 정답률 0.83914\n",
      "알파값 3.57 정답률 0.83912\n",
      "알파값 3.58 정답률 0.8391\n",
      "알파값 3.59 정답률 0.83906\n",
      "알파값 3.6 정답률 0.83904\n",
      "알파값 3.61 정답률 0.839\n",
      "알파값 3.62 정답률 0.839\n",
      "알파값 3.63 정답률 0.83898\n",
      "알파값 3.64 정답률 0.83898\n",
      "알파값 3.65 정답률 0.83888\n",
      "알파값 3.66 정답률 0.83888\n",
      "알파값 3.67 정답률 0.8389\n",
      "알파값 3.68 정답률 0.83892\n",
      "알파값 3.69 정답률 0.83892\n",
      "알파값 3.7 정답률 0.83894\n",
      "알파값 3.71 정답률 0.83896\n",
      "알파값 3.72 정답률 0.839\n",
      "알파값 3.73 정답률 0.83898\n",
      "알파값 3.74 정답률 0.83896\n",
      "알파값 3.75 정답률 0.83898\n",
      "알파값 3.76 정답률 0.839\n",
      "알파값 3.77 정답률 0.83904\n",
      "알파값 3.78 정답률 0.83902\n",
      "알파값 3.79 정답률 0.839\n",
      "알파값 3.8 정답률 0.839\n",
      "알파값 3.81 정답률 0.839\n",
      "알파값 3.82 정답률 0.83898\n",
      "알파값 3.83 정답률 0.83892\n",
      "알파값 3.84 정답률 0.83894\n",
      "알파값 3.85 정답률 0.83892\n",
      "알파값 3.86 정답률 0.8389\n",
      "알파값 3.87 정답률 0.83892\n",
      "알파값 3.88 정답률 0.8389\n",
      "알파값 3.89 정답률 0.83886\n",
      "알파값 3.9 정답률 0.83888\n",
      "알파값 3.91 정답률 0.83888\n",
      "알파값 3.92 정답률 0.83888\n",
      "알파값 3.93 정답률 0.83886\n",
      "알파값 3.94 정답률 0.83884\n",
      "알파값 3.95 정답률 0.83886\n",
      "알파값 3.96 정답률 0.8388\n",
      "알파값 3.97 정답률 0.83874\n",
      "알파값 3.98 정답률 0.83874\n",
      "알파값 3.99 정답률 0.83876\n",
      "알파값 4.0 정답률 0.8388\n",
      "\n",
      "최적의 정답률 일때 알파값 =  2.44 최적의 정답률 =  0.83926\n"
     ]
    }
   ],
   "source": [
    "#알파값을 1.0부터 0.01씩 더해가면서 알파값과 정답률을 출력하면서 확인\n",
    "x=1.0\n",
    "\n",
    "for i in range(300):\n",
    "    nb=MultinomialNB(alpha=x)\n",
    "    nb.fit(x_train, y_train)\n",
    "    pre=nb.predict(x_test)\n",
    "    ac_score=metrics.accuracy_score(y_test,pre)\n",
    "    x=x+0.01\n",
    "    print(\"알파값\", round(x,2), \"정답률\", ac_score)\n",
    "    i=i+1\n",
    "\n",
    "print()\n",
    "print(\"최적의 정답률 일때 알파값 = \", 2.44, \"최적의 정답률 = \", 0.83926)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#알파값을 1.0부터 0.01씩 더해가면서 알파값과 정답률을 numpy array에 append시키고 점그래프로 시각화\n",
    "x=1.0\n",
    "x1=np.array([])\n",
    "y1=np.array([])\n",
    "\n",
    "ans=0\n",
    "for i in range(300):\n",
    "    nb=MultinomialNB(alpha=x)\n",
    "    nb.fit(x_train, y_train)\n",
    "    pre=nb.predict(x_test)\n",
    "    ac_score=metrics.accuracy_score(y_test,pre)\n",
    "    x=x+0.01\n",
    "    x1 = np.append(x1, np.array([x]))\n",
    "    y1 = np.append(y1, np.array([ac_score]))\n",
    "    i=i+1\n",
    "plt.plot(x1,y1,'go')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
