Kafka: a Distributed Messaging System for Log Processing   Kafka는 로그 데이터를 수집하고 전달하는 데 사용되며, 대량의 데이터를 저지연 시간으로 처리할 수 있다
There is a large amount of “log” data generated at any sizable  internet company. This data typically includes (1) user activity  events corresponding to logins, pageviews, clicks, “likes”,  sharing, comments, and search queries; (2) operational metrics  such as service call stack, call latency, errors, and system metrics  such as CPU, memory, network, or disk utilization on each  machine. Log data has long been a component of analytics used to  track user engagement, system utilization, and other metrics.  However recent trends in internet applications have made activity  data a part of the production data pipeline used directly in site  features. These uses include (1) search relevance, (2)  recommendations which may be driven by item popularity or cooccurrence in the activity stream, (3) ad targeting and reporting,  and (4) security applications that protect against abusive behaviors  such as spam or unauthorized data scraping, and (5) newsfeed  features that aggregate user status updates or actions for their  “friends” or “connections” to read.  This production, real-time usage of log data creates new  challenges for data systems because its volume is orders of  magnitude larger than the “real” data. For example, search,  recommendations, and advertising often require computing    Permission to make digital or hard copies of all or part of this work for  personal or classroom use is granted without fee provided that copies are  not made or distributed for profit or commercial advantage and that  copies bear this notice and the full citation on the first page. To copy  otherwise, or republish, to post on servers or to redistribute to lists,  requires prior specific permission and/or a fee.  granular click-through rates, which generate log records not only  for every user click, but also for dozens of items on each page that  are not clicked. Every day, China Mobile collects 5–8TB of phone  call records [11] and Facebook gathers almost 6TB of various user  activity events [12]  Many early systems for processing this kind of data relied on  physically scraping log files off production servers for analysis. In  recent years, several specialized distributed log aggregators have  been built, including Facebook’s Scribe [6], Yahoo’s Data  Highway [4], and Cloudera’s Flume [3]. Those systems are  primarily designed for collecting and loading the log data into a  data warehouse or Hadoop [8] for offline consumption. At  LinkedIn (a social network site), we found that in addition to  traditional offline analytics, we needed to support most of the  real-time applications mentioned above with delays of no more  than a few seconds.  We have built a novel messaging system for log processing called  Kafka [18] that combines the benefits of traditional log  aggregators and messaging systems. On the one hand, Kafka is  distributed and scalable, and offers high throughput. On the other  hand, Kafka provides an API similar to a messaging system and  allows applications to consume log events in real time. Kafka has  been open sourced and used successfully in production at  LinkedIn for more than 6 months. It greatly simplifies our  infrastructure, since we can exploit a single piece of software for  both online and offline consumption of the log data of all types.  The rest of the paper is organized as follows. We revisit  traditional messaging systems and log aggregators in Section 2. In  Section 3, we describe the architecture of Kafka and its key design  principles. We describe our deployment of Kafka at LinkedIn in  Section 4 and the performance results of Kafka in Section 5. We  discuss future work and conclude in Section 6.   ### Kafka Architecture and Design Principles  Because of limitations in existing systems, we developed a new  messaging-based log aggregator Kafka. We first introduce the  basic concepts in Kafka. A stream of messages of a particular type  is defined by a topic. A producer can publish messages to a topic.  The published messages are then stored at a set of servers called  brokers. A consumer can subscribe to one or more topics from the  brokers, and consume the subscribed messages by pulling data  from the brokers.  Messaging is conceptually simple, and we have tried to make the  Kafka API equally simple to reflect this. Instead of showing the  exact API, we present some sample code to show how the API is  used. The sample code of the producer is given below. A message  is defined to contain just a payload of bytes. A user can choose  her favorite serialization method to encode a message. For  efficiency, the producer can send a set of messages in a single  publish request.

===========================

To subscribe to a topic, a consumer first creates one or more  message streams for the topic. The messages published to that  topic will be evenly distributed into these sub-streams. The details  about how Kafka distributes the messages are described later in  Section 3.2. Each message stream provides an iterator interface  over the continual stream of messages being produced. The  consumer then iterates over every message in the stream and  processes the payload of the message. Unlike traditional iterators,  the message stream iterator never terminates. If there are currently  no more messages to consume, the iterator blocks until new  messages are published to the topic. We support both the point-topoint delivery model in which multiple consumers jointly  consume a single copy of all messages in a topic, as well as the  publish/subscribe model in which multiple consumers each  retrieve its own copy of a topic.

=============================

The overall architecture of Kafka is shown in Figure 1. Since Kafka is distributed in nature, an Kafka cluster typically consists  of multiple brokers. To balance load, a topic is divided into multiple partitions and each broker stores one or more of those  partitions. Multiple producers and consumers can publish and  retrieve messages at the same time. In Section 3.1, we describe the  layout of a single partition on a broker and a few design choices  that we selected to make accessing a partition efficient. In Section  3.2, we describe how the producer and the consumer interact with  multiple brokers in a distributed setting. We discuss the delivery  guarantees of Kafka in Section 3.3.

==================================

### 3.1 Efficiency on a Single Partition
Simple storage: Kafka has a very simple storage layout. Each  partition of a topic corresponds to a logical log. Physically, a log  is implemented as a set of segment files of approximately the  same size (e.g., 1GB). Every time a producer publishes a message  to a partition, the broker simply appends the message to the last  segment file. For better performance, we flush the segment files to  disk only after a configurable number of messages have been  published or a certain amount of time has elapsed. A message is  only exposed to the consumers after it is flushed.  Unlike typical messaging systems, a message stored in Kafka  doesn’t have an explicit message id. Instead, each message is  addressed by its logical offset in the log. This avoids the overhead  of maintaining auxiliary, seek-intensive random-access index  structures that map the message ids to the actual message  locations. Note that our message ids are increasing but not  consecutive. To compute the id of the next message, we have to  add the length of the current message to its id. From now on, we  will use message ids and offsets interchangeably.  A consumer always consumes messages from a particular  partition sequentially. If the consumer acknowledges a particular  message offset, it implies that the consumer has received all  messages prior to that offset in the partition. Under the covers, the  consumer is issuing asynchronous pull requests to the broker to  have a buffer of data ready for the application to consume. Each  pull request contains the offset of the message from which the  consumption begins and an acceptable number of bytes to fetch.  Each broker keeps in memory a sorted list of offsets, including the  offset of the first message in every segment file. The broker  locates the segment file where the requested message resides by  searching the offset list, and sends the data back to the consumer.  After a consumer receives a message, it computes the offset of the  next message to consume and uses it in the next pull request. The  layout of an Kafka log and the in-memory index is depicted in  Figure 2. Each box shows the offset of a message.
====================================
Efficient transfer: We are very careful about transferring data in  and out of Kafka. Earlier, we have shown that the producer can  submit a set of messages in a single send request. Although the  end consumer API iterates one message at a time, under the  covers, each pull request from a consumer also retrieves multiple  messages up to a certain size, typically hundreds of kilobytes.  Another unconventional choice that we made is to avoid explicitly  caching messages in memory at the Kafka layer. Instead, we rely  on the underlying file system page cache. This has the main  benefit of avoiding double buffering---messages are only cached  in the page cache. This has the additional benefit of retaining  warm cache even when a broker process is restarted. Since Kafka  doesn’t cache messages in process at all, it has very little overhead  in garbage collecting its memory, making efficient  implementation in a VM-based language feasible. Finally, since  both the producer and the consumer access the segment files  sequentially, with the consumer often lagging the producer by a  small amount, normal operating system caching heuristics are  very effective (specifically write-through caching and readahead). We have found that both the production and the  consumption have consistent performance linear to the data size,  up to many terabytes of data.  In addition we optimize the network access for consumers. Kafka  is a multi-subscriber system and a single message may be  consumed multiple times by different consumer applications. A  typical approach to sending bytes from a local file to a remote  socket involves the following steps: (1) read data from the storage  media to the page cache in an OS, (2) copy data in the page cache  to an application buffer, (3) copy application buffer to another  kernel buffer, (4) send the kernel buffer to the socket. This  includes 4 data copying and 2 system calls. On Linux and other  Unix operating systems, there exists a sendfile API [5] that can  directly transfer bytes from a file channel to a socket channel.  This typically avoids 2 of the copies and 1 system call introduced  in steps (2) and (3). Kafka exploits the sendfile API to efficiently  deliver bytes in a log segment file from a broker to a consumer.  Stateless broker: Unlike most other messaging systems, in  Kafka, the information about how much each consumer has  consumed is not maintained by the broker, but by the consumer  itself. Such a design reduces a lot of the complexity and the  overhead on the broker. However, this makes it tricky to delete a  message, since a broker doesn’t know whether all subscribers  have consumed the message. Kafka solves this problem by using a  simple time-based SLA for the retention policy. A message is  automatically deleted if it has been retained in the broker longer  than a certain period, typically 7 days. This solution works well in  practice. Most consumers, including the offline ones, finish  consuming either daily, hourly, or in real-time. The fact that the  performance of Kafka doesn’t degrade with a larger data size  makes this long retention feasible.  There is an important side benefit of this design. A consumer can  deliberately rewind back to an old offset and re-consume data.  This violates the common contract of a queue, but proves to be an  essential feature for many consumers. For example, when there is  an error in application logic in the consumer, the application can  re-play certain messages after the error is fixed. This is  particularly important to ETL data loads into our data warehouse  or Hadoop system. As another example, the consumed data may  be flushed to a persistent store only periodically (e.g, a full-text  indexer). If the consumer crashes, the unflushed data is lost. In  this case, the consumer can checkpoint the smallest offset of the  unflushed messages and re-consume from that offset when it’s  restarted. We note that rewinding a consumer  is much easier to support in the pull model than the push model.